# -Caroline-menard
<p align="right">
  <img src="https://github.com/Caroline-menard/-Caroline-menard/blob/main/logo_blanc.png?raw=true" alt="Logo Caroline MÃ©nard" width="160">
</p>

### ğŸ‘‹ Salut, moi câ€™est Caroline

Jâ€™ai dâ€™abord enseignÃ© les mathÃ©matiques avant de plonger dans lâ€™univers fascinant des donnÃ©es.  

Curieuse de nature et amoureuse des mots, je suis aujourdâ€™hui data scientist spÃ©cialisÃ©e en NLP, au sein de la startup **U change**.  
Je conÃ§ois des outils qui Ã©coutent, trient, expliquent, Ã  partir dâ€™un immense fouillis de donnÃ©es textuelles.  
Mes projets mÃªlent rigueur analytique, traitement du langage et sens du dÃ©tail.

### ğŸ§ª Ce portfolio prÃ©sente mes projets personnels  
Parce que les projets perso nourrissent les compÃ©tences pro â€” et inversement.  
Explorer, apprendre, rater, rÃ©ussir : ici, tout est prÃ©texte Ã  progresser.

> *â€œOnce you stop learning, you start dying.â€*  
> â€” Albert Einstein

Bienvenue dans mon monde mi-algo, mi-poÃ©sie...

# 1- Amazon Review Classifier & Dashboard

ğŸ‘‰ [DÃ©couvrir le projet sur GitHub](https://github.com/Caroline-menard/amazon_review_classifier_and_Dashboard)

**Classification** automatique dâ€™avis clients et visualisation interactive via **Streamlit**.

Ce projet NLP dÃ©tecte plusieurs typologies de problÃ¨mes dans des revues Amazon (produit endommagÃ©, non conforme, etc.) grÃ¢ce Ã  une pipeline combinant TF-IDF, features sÃ©mantiques, et XGBoost.

RÃ©sultats explorables dans un dashboard, avec filtres, graphiques et export de donnÃ©es.

## CompÃ©tences mobilisÃ©es dans ce projet
*Traitement automatique du langage (NLP) :*
> â€” Nettoyage et prÃ©paration de texte, TfidfVectorizer, RÃ©duction de dimension avec TruncatedSVD.

*Machine Learning multi-label :*
> â€” Construction dâ€™un pipeline scikit-learn modulaire.<br>
> â€”  EntraÃ®nement et validation croisÃ©e (GridSearchCV).

*Feature engineering :*
> â€” CrÃ©ation de features via FunctionTransformer<br>
> â€” classes personnalisÃ©es de preprocessing et post-processing.

*Manipulation de donnÃ©es:*
> â€” Avec pandas,numpy <br>
> â€” Fichiers parquet optimisÃ©s pour le stockage.

*Data Engineering (light) :*
> â€” Interaction avec une base PostgreSQL hÃ©bergÃ©e sur Supabase.<br>
> â€”  Scripts dâ€™ETL pour lâ€™insertion et la mise Ã  jour des prÃ©dictions.

*Visualisation et restitution interactive :*
> â€” CrÃ©ation dâ€™un dashboard interactif Streamlit.<br>
> â€” Visualisation de rÃ©sultats, filtres dynamiques, export de donnÃ©es.

*DÃ©ploiement :*
> â€” HÃ©bergement du dashboard sur Streamlit Cloud.<br>
> â€” Optimisation des requirements.txt pour la compatibilitÃ© serveur.

*Organisation projet / bonnes pratiques :*
> â€” Modularisation des scripts (prediction, ETL, orchestration).<br>
> â€”  .gitignore propre, README dÃ©taillÃ©, visualisation dâ€™architecture.<br>
> â€” RÃ©fÃ©rencement clair des dÃ©pendances et workflow reproductible.<br>
> - ğŸ§˜ Patience et tÃ©nacitÃ©, indispensables pour dompter les caprices de Streamlit Cloud Ã  2h du matâ€™.
